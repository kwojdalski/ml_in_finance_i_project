{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "eca02445",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Stock Market Movement Prediction - Data Science](#toc0_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93447067",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Stock Market Movement Prediction - Data Science](#toc1_1_)    \n",
    "    - [Environment Setup](#toc1_1_1_)    \n",
    "  - [Library Imports](#toc1_2_)    \n",
    "      - [Helper Function](#toc1_2_1_1_)    \n",
    "    - [Loading Up Kedro Config](#toc1_2_2_)    \n",
    "    - [Getting Data from the Data Processing Pipeline](#toc1_2_3_)    \n",
    "  - [Split Data into Training and Test Sets](#toc1_3_)    \n",
    "  - [Basic Decision Tree Model](#toc1_4_)    \n",
    "    - [Fitting Baseline Model](#toc1_4_1_)    \n",
    "    - [Tuning Decision Tree Model with GridSearch](#toc1_4_2_)    \n",
    "    - [Feature Selection for the Tuned Model](#toc1_4_3_)    \n",
    "  - [Visualize Feature Importance](#toc1_5_)    \n",
    "  - [Decision Tree Tuned Model](#toc1_6_)    \n",
    "    - [Prediction on the Test Dataframe](#toc1_6_1_)    \n",
    "  - [Gradient Boosting Classifier](#toc1_7_)    \n",
    "    - [Tuning Parameters with GridSearch](#toc1_7_1_)    \n",
    "    - [Parameters Tuning](#toc1_7_2_)    \n",
    "    - [Run Sequential Parameter Tuning](#toc1_7_3_)    \n",
    "      - [Use the Model with Best Parameters](#toc1_7_3_1_)    \n",
    "  - [Neural Network](#toc1_8_)    \n",
    "    - [Decisions About Architecture](#toc1_8_1_)    \n",
    "    - [Running the Model](#toc1_8_2_)    \n",
    "  - [Model Comparison Plot](#toc1_9_)    \n",
    "    - [Simulation](#toc1_9_1_)    \n",
    "  - [Key Findings](#toc1_10_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_1_1_'></a>[Environment Setup](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26756220",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    # If we're in VSCode, find the src path this way\n",
    "    path = Path(__file__).parent.parent\n",
    "    path = path / \"src\"\n",
    "except NameError:\n",
    "    # If we're in Jupyter, find the path this way instead\n",
    "    path = Path().absolute().parent\n",
    "\n",
    "sys.path.append(str(path))\n",
    "\n",
    "import kedro.ipython\n",
    "from kedro.ipython import get_ipython\n",
    "\n",
    "kedro.ipython.load_ipython_extension(get_ipython())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Library Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3528670",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging as log\n",
    "import sys\n",
    "\n",
    "import kedro.ipython\n",
    "import torch\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from src.ml_in_finance_i_project.pipelines.data_science.nodes import model_fit\n",
    "from src.ml_in_finance_i_project.utils import get_node_idx, get_node_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <a id='toc1_2_1_1_'></a>[Helper Function](#toc0_)\n",
    "- Run pipeline nodes right here in the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402c8261",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_node(pipeline_name: str, node_name: str, inputs: dict):\n",
    "    \"\"\"Run a specific node from a pipeline.\"\"\"\n",
    "    from kedro.framework.session import KedroSession\n",
    "\n",
    "    with KedroSession.create() as session:\n",
    "        context = session.load_context()\n",
    "        pipeline = context.pipelines[pipeline_name]\n",
    "        node = [n for n in pipeline.nodes if n.name == node_name][0]\n",
    "        return node.run(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_2_'></a>[Loading Up Kedro Config](#toc0_)\n",
    "Grab all our parameters from the config file\n",
    "* This has elements like our target variable and k-fold settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70024ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf_params = context.config_loader.get(\"parameters\")\n",
    "target = conf_params[\"model_options\"][\"target\"]\n",
    "kfold = conf_params[\"model_options\"][\"kfold\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_3_'></a>[Getting Data from the Data Processing Pipeline](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0d3436",
   "metadata": {},
   "outputs": [],
   "source": [
    "out9 = get_node_outputs(\n",
    "    pipelines[\"data_processing\"].nodes[\n",
    "        get_node_idx(pipelines[\"data_processing\"], \"remove_duplicates_and_nans_node\")\n",
    "    ],\n",
    "    catalog,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Split Data into Training and Test Sets](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ba5da",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "out10 = run_pipeline_node(\n",
    "    \"data_science\",\n",
    "    \"split_data_node\",\n",
    "    {\n",
    "        \"train_df_clean\": out9[\"train_df_clean\"],\n",
    "        \"params:model_options\": conf_params[\"model_options\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3f2de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = out10[\"X_train\"]\n",
    "X_test = out10[\"X_test\"]\n",
    "y_train = out10[\"y_train\"]\n",
    "y_test = out10[\"y_test\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Basic Decision Tree Model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "887ef47c",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dt = run_pipeline_node(\n",
    "    \"data_science\",\n",
    "    \"train_decision_tree_node\",\n",
    "    {\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"parameters\": conf_params,\n",
    "    },\n",
    ")[\"base_dt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_1_'></a>[Fitting Baseline Model](#toc0_)\n",
    "The model_fit() function does the following:\n",
    "- Trains the model and makes predictions\n",
    "- Shows us how well it's doing with confusion matrix and accuracy\n",
    "- Does cross-validation to check if we're overfitting\n",
    "- Draws ROC curves to visualize performance\n",
    "- Shows which features are most important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1b1e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(f\"Accuracy on test set: {base_dt['model'].score(X_test, y_test):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_2_'></a>[Tuning Decision Tree Model with GridSearch](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4426e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_dt = run_pipeline_node(\n",
    "    \"data_science\",\n",
    "    \"tune_decision_tree_node\",\n",
    "    {\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"parameters\": conf_params,\n",
    "    },\n",
    ")[\"grid_dt\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd0e463",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_3_'></a>[Feature Selection for the Tuned Model](#toc0_)\n",
    "Based on feature importances"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Visualize Feature Importance](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b3c381",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline_node(\n",
    "    \"reporting\",\n",
    "    \"plot_feature_importance_node\",\n",
    "    {\n",
    "        \"grid_dt\": tuned_dt,\n",
    "        \"X_train\": X_train,\n",
    "        \"params:feature_importance_threshold\": conf_params[\"model_options\"][\n",
    "            \"feature_importance_threshold\"\n",
    "        ],\n",
    "    },\n",
    ")[\"feature_importance_plot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8250d249",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "**Filtering Out Features with Less Than 1% of Feature Importance**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13630e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "out12 = run_pipeline_node(\n",
    "    \"data_science\",\n",
    "    \"select_important_features_node\",\n",
    "    {\n",
    "        \"X_train\": X_train,\n",
    "        \"X_test\": X_test,\n",
    "        \"grid_dt\": tuned_dt,\n",
    "        \"parameters\": conf_params,\n",
    "    },\n",
    ")\n",
    "X_train_selected = out12[\"X_train_selected\"]\n",
    "X_test_selected = out12[\"X_test_selected\"]\n",
    "important_features = out12[\"important_features\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Decision Tree Tuned Model](#toc0_)\n",
    "New sets with only the selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017f2324",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_dt = run_pipeline_node(\n",
    "    \"data_science\",\n",
    "    \"tune_decision_tree_selected_node\",\n",
    "    {\n",
    "        \"X_train_selected\": X_train_selected,\n",
    "        \"y_train\": y_train,\n",
    "        \"parameters\": conf_params,\n",
    "    },\n",
    ")[\"grid_dt_selected\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3e7498",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"Fitting with train set\")\n",
    "model_fit(\n",
    "    grid_dt[\"model\"],\n",
    "    X_train_selected,\n",
    "    y_train,\n",
    "    X_train_selected.columns,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da4ce8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "log.info(\"Fitting with test set\")\n",
    "model_fit(\n",
    "    tuned_dt[\"model\"],\n",
    "    X_test_selected,\n",
    "    y_test,\n",
    "    important_features,\n",
    "    roc=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_1_'></a>[Prediction on the Test Dataframe](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d388865",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "prediction = grid_dt[\"model\"].predict(X_test_selected)\n",
    "log.info(f\"{prediction}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0be54bd9",
   "metadata": {},
   "source": [
    "## <a id='toc1_7_'></a>[Gradient Boosting Classifier](#toc0_)\n",
    "* `HistGradientBoostingClassifier` used as it is faster than `GradientBoostingClassifier`\n",
    "* All the features are used\n",
    "* Remove parameters not accepted by `HistGradientBoostingClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_7_1_'></a>[Tuning Parameters with GridSearch](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0e6c27",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "\n",
    "gbm_classifier = run_pipeline_node(\n",
    "    \"data_science\",\n",
    "    \"train_gradient_boosting_node\",\n",
    "    {\n",
    "        \"X_train_selected\": X_train_selected,\n",
    "        \"y_train\": y_train,\n",
    "        \"parameters\": conf_params,\n",
    "    },\n",
    ")[\"base_gb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "988a6108",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit(\n",
    "    gbm_classifier[\"model\"].model,\n",
    "    X_train_selected,\n",
    "    y_train,\n",
    "    important_features,\n",
    "    roc=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97d723c",
   "metadata": {},
   "source": [
    "### <a id='toc1_7_2_'></a>[Parameters Tuning](#toc0_)\n",
    "Steps:\n",
    "1. n_estimators (30-80): Number of boosting stages to perform\n",
    "2. max_depth (5-15): Maximum depth of individual trees\n",
    "3. min_samples_split (400-1000): Minimum samples required to split internal node\n",
    "4. min_samples_leaf (40): Minimum samples required at leaf node\n",
    "5. max_features (7-20): Number of features to consider for best split\n",
    "6. Fixed parameters:\n",
    "   - learning_rate=0.1\n",
    "   - subsample=0.8\n",
    "   - random_state=10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_7_3_'></a>[Run Sequential Parameter Tuning](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3d5469",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuned_gb = run_pipeline_node(\n",
    "    \"data_science\",\n",
    "    \"tune_gradient_boosting_node\",\n",
    "    {\n",
    "        \"base_gb\": gbm_classifier[\"model\"],\n",
    "        \"X_train_selected\": X_train_selected,\n",
    "        \"y_train\": y_train,\n",
    "        \"parameters\": conf_params,\n",
    "    },\n",
    ")[\"tuned_gb\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaa4c081",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_estimators_result = tuned_gb[\"n_estimators_result\"]\n",
    "tree_params_result = tuned_gb[\"tree_params_result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef503b2d",
   "metadata": {},
   "source": [
    "Results from Previous Run (HistGradientBoostingClassifier):\n",
    "Best: 0.5368177574059928 using {'max_depth': 9, 'min_samples_leaf': 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fae7f31",
   "metadata": {},
   "outputs": [],
   "source": [
    "leaf_params_result = tuned_gb[\"leaf_params_result\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best (Simple TA): 0.578087598675834 using {'l2_regularization': 0.001}\n",
    "#### <a id='toc1_7_3_1_'></a>[Use the Model with Best Parameters](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f480f7",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "max_features_result = tuned_gb[\"max_features_result\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fit(\n",
    "    max_features_result.best_estimator_,\n",
    "    X_train_selected,\n",
    "    y_train,\n",
    "    X_train_selected.columns,\n",
    "    roc=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70c4d24",
   "metadata": {},
   "source": [
    "## <a id='toc1_8_'></a>[Neural Network](#toc0_)\n",
    "* Standardization of the data\n",
    "* Initialize model, loss function and optimizer\n",
    "Convert data to tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f126052",
   "metadata": {},
   "source": [
    "### <a id='toc1_8_1_'></a>[Decisions About Architecture](#toc0_)\n",
    "* Tanh has been used in the first two layers because it outputs values from -1 to 1, which can be beneficial\n",
    "for centered data.\n",
    "* ReLU is used in the later layers since it helps to mitigate the vanishing gradient problem\n",
    "and enhances computational efficiency.\n",
    "* Sigmoid in the final layer is used for binary classification tasks,\n",
    "where you want to output a probability between 0 and 1.\n",
    "* Dropout is used to prevent overfitting.\n",
    "* The use of different activation functions (Tanh, ReLU, Sigmoid) introduces non-linearity into the model.\n",
    "* Tanh is typically used in the first two layers because it outputs values between -1 and 1,\n",
    "which can be beneficial for centered data.\n",
    "* ReLU (Rectified Linear Unit) is generally used in the later layers since it helps to mitigate\n",
    "the vanishing gradient problem and enhances computational efficiency.\n",
    "\n",
    "Layers:\n",
    "* **5** layers\n",
    "* **100** neurons in the first layer (Tanh)\n",
    "* **50** neurons in the second layer (Tanh) with dropout (0.33)\n",
    "* **150** neurons in the third layer (ReLU)\n",
    "* **50** neurons in the fourth layer (ReLU)\n",
    "* **35** neurons in the fifth layer (Sigmoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_8_2_'></a>[Running the Model](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7a4ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_model = run_pipeline_node(\n",
    "    \"data_science\",\n",
    "    \"train_neural_network_node\",\n",
    "    {\n",
    "        \"X_train\": X_train,\n",
    "        \"y_train\": y_train,\n",
    "        \"parameters\": conf_params,\n",
    "    },\n",
    ")[\"nn_model\"]\n",
    "\n",
    "X_test_tensor = torch.FloatTensor(X_test.values)\n",
    "y_test_tensor = torch.FloatTensor(y_test.values).reshape(-1, 1)\n",
    "with torch.no_grad():\n",
    "    outputs = nn_model[\"model\"](X_test_tensor)\n",
    "    # Convert probabilities to binary predictions using 0.5 threshold\n",
    "    y_predict = (outputs >= 0.5).squeeze().numpy()\n",
    "\n",
    "# y_predict.to_csv(\"data/07_model_output/y_predict.csv\", index=False)\n",
    "print(classification_report(y_test_tensor, y_predict, digits=5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_9_'></a>[Model Comparison Plot](#toc0_)\n",
    "Convert model results to DataFrame for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12e19fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_results = run_pipeline_node(\n",
    "    \"reporting\",\n",
    "    \"aggregate_model_results_node\",\n",
    "    {\n",
    "        \"base_dt\": base_dt,\n",
    "        \"grid_dt\": grid_dt,\n",
    "        \"tuned_gb\": tuned_gb,\n",
    "        \"nn_model\": nn_model,\n",
    "        \"X_test\": X_test,\n",
    "        \"y_test\": y_test,\n",
    "    },\n",
    ")[\"model_results\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5083d904",
   "metadata": {},
   "source": [
    "Create Dictionary of Model Results Including Stepping Stone Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a76537",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline_node(\n",
    "    \"reporting\",\n",
    "    \"plot_model_accuracy_node\",\n",
    "    {\n",
    "        \"model_results\": model_results,\n",
    "    },\n",
    ")[\"model_accuracy_plot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_9_1_'></a>[Simulation](#toc0_)\n",
    "Simulation of actual returns based on predictions coming from models.\n",
    "It must be stated that there are a few assumptions:\n",
    "* Zero transaction costs\n",
    "* No slippage (no market impact)\n",
    "* Unconstrained shorting\n",
    "Takeaways:\n",
    "- If, on average, we are right >50% of the time, and the sizing of the trade is constant,\n",
    "then we can expect to make money. Hence, the line with some positive drift is expected.\n",
    "- The slope of this line depends on the accuracy of the model. The higher the accuracy, the higher the slope.\n",
    "- As previously stated, this is a very simplified model and does not take into account many factors\n",
    "that could affect the real performance of the strategy.\n",
    "- The scope of this project is limited, i.e. to generate a buy/sell signal that in real application\n",
    "is just a small part of actual trading decision."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e532280a",
   "metadata": {},
   "source": [
    "Run Simulation\n",
    "run_pipeline_node(\n",
    "    \"reporting\",\n",
    "    \"simulate_strategy_node\",\n",
    "    {\n",
    "        \"y_test\": y_test,\n",
    "        \"y_predict\": y_predict,\n",
    "        \"params:n_simulations\": 1,\n",
    "        \"params:n_days\": 100,\n",
    "    },\n",
    ")[\"strategy_simulation_plot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051d2a00",
   "metadata": {},
   "source": [
    "max_features_result.best_estimator_.predict(out9[\"test_df_clean\"][important_features])\n",
    "y_pred = max_features_result.best_estimator_.predict_proba(\n",
    "    out9[\"test_df_clean\"][important_features].fillna(0)\n",
    ")[:, 1]\n",
    "sub = out9[\"test_df_clean\"].copy()\n",
    "sub[\"pred\"] = y_pred\n",
    "y_pred = sub[\"pred\"].transform(lambda x: x > x.median()).values\n",
    "\n",
    "submission = pd.Series(y_pred)\n",
    "submission.index = sub.index\n",
    "submission.name = target\n",
    "\n",
    "submission.to_csv(\"./data/07_model_output/submission.csv\", index=True, header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_10_'></a>[Key Findings](#toc0_)\n",
    "\n",
    "- All models are compared against the benchmark accuracy of 51.31%\n",
    "   + It's not a perfect benchmark as the number comes from completely unseen data while\n",
    "   models performance is evaluated on the part of the training set\n",
    "- The tuned Gradient Boosting model significantly outperforms other models\n",
    "   + But when submitted via QRT data challenge the performance wasn't great (**0.5066**)\n",
    "- Hyperparameter tuning improved both Decision Tree and Gradient Boosting performance\n",
    "- Gradient Boosting shows superior performance compared to Decision Trees, which is expected\n",
    "- HistGradientBoostingClassifier is much faster than GradientBoostingClassifier without\n",
    "  much compromising the performance\n",
    "- Further improvement in out-of-sample performance is possible by both\n",
    "better feature engineering and further hyperparameter tuning\n",
    "   * More technical indicators could be introduced (e.g. ROC, Golden Cross, etc.)\n",
    "   * More variables based on the categorical variables (which are dropped as of now)\n",
    "could bring in some value\n",
    "- Even simple technical indicators can improve the performance of the model more than right choice of hyperparameters\n",
    "- Using too many features caused extreme overfitting (expected)\n",
    "- Incorrectly calculated technical indicators had some predictive power (unexpected)\n",
    "- Neural network-based model is not able to beat the benchmark accuracy of 51.31% (NN was only marginally better)\n",
    "- More sophisticated MLOps tools would be useful to track the performance of the model and the changes in the code"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
