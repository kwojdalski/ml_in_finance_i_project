{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9b7a78a",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Stock Market Movement Prediction](#toc0_)\n",
    "### <a id='toc1_1_1_'></a>[Using ML Techniques to Forecast Next-Day Stock Price Movements](#toc0_)\n",
    "\n",
    "This project tackles a challenging binary classification problem in quantitative finance - predicting the directional movement\n",
    "(up or down) of individual US stocks for the following trading day. The goal is to develop a machine learning model\n",
    "that can provide data-driven insights to support investment decision-making.\n",
    "\n",
    "The model leverages a feature set including:\n",
    "- **20** days of historical price returns\n",
    "- **20** days of trading volume data\n",
    "- Categorical stock metadata (industry, sector, etc.)\n",
    "- Technical indicators and statistical features\n",
    "\n",
    "A public benchmark accuracy of **51.31%** was previously achieved using a Random Forest model with **5** days of historical data and\n",
    "sector-level information. Our approach aims to improve upon this by incorporating more features and advanced modeling techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7785305a",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Stock Market Movement Prediction](#toc1_)    \n",
    "    - [Using ML Techniques to Forecast Next-Day Stock Price Movements](#toc1_1_1_)    \n",
    "  - [Data Description](#toc1_2_)    \n",
    "    - [Input Dataset Structure](#toc1_2_1_)    \n",
    "    - [Output Dataset Structure](#toc1_2_2_)    \n",
    "    - [Key Financial Calculations](#toc1_2_3_)    \n",
    "    - [Dataset Scale](#toc1_2_4_)    \n",
    "    - [Submission Guidelines](#toc1_2_5_)    \n",
    "  - [Implementation Strategy](#toc1_3_)    \n",
    "      - [Project Roadmap](#toc1_3_1_1_)    \n",
    "  - [Library Imports](#toc1_4_)    \n",
    "    - [Environment Configuration and Setup](#toc1_4_1_)    \n",
    "      - [Pipeline Node Execution Configuration](#toc1_4_1_1_)    \n",
    "        - [Environment Initialization](#toc1_4_1_1_1_)    \n",
    "  - [Data Loading and Initial Processing](#toc1_5_)    \n",
    "    - [Preprocessing Strategy](#toc1_5_1_)    \n",
    "      - [Visual Data Analysis](#toc1_5_1_1_)    \n",
    "      - [Initial Data Inspection](#toc1_5_1_2_)    \n",
    "      - [Dataset Information](#toc1_5_1_3_)    \n",
    "    - [Missing Value Across Categories](#toc1_5_2_)    \n",
    "      - [Possible Causes of Missing Data](#toc1_5_2_1_)    \n",
    "      - [Class Balance Analysis](#toc1_5_2_2_)    \n",
    "      - [Correlation Analysis](#toc1_5_2_3_)    \n",
    "    - [Key Findings:](#toc1_5_3_)    \n",
    "    - [Preprocessing data](#toc1_5_4_)    \n",
    "  - [Feature Engineering](#toc1_6_)    \n",
    "    - [Technical Indicator Implementation Using TA-Lib](#toc1_6_1_)    \n",
    "      - [Implemented Indicators:](#toc1_6_1_1_)    \n",
    "    - [Feature Selection Strategy](#toc1_6_2_)    \n",
    "      - [Columns Targeted for Removal](#toc1_6_2_1_)    \n",
    "    - [Technical Indicator Optimization](#toc1_6_3_)    \n",
    "      - [Indicator Selection Criteria](#toc1_6_3_1_)    \n",
    "    - [Data Quality Enhancement](#toc1_6_4_)    \n",
    "      - [Infinity Value Management](#toc1_6_4_1_)    \n",
    "    - [Final Data Cleaning](#toc1_6_5_)    \n",
    "      - [Quality Assurance Steps](#toc1_6_5_1_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eb14e84",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Data Description](#toc0_)\n",
    "\n",
    "The project utilizes three primary datasets provided in CSV format, split between training (inputs/outputs) and test inputs.\n",
    "\n",
    "### <a id='toc1_2_1_'></a>[Input Dataset Structure](#toc0_)\n",
    "* **Identifier Features:**\n",
    "  - ID: Unique row identifier\n",
    "  - DATE: Anonymized date index\n",
    "  - STOCK: Stock identifier\n",
    "\n",
    "* **Categorical Features:**\n",
    "  - INDUSTRY: Stock's primary industry classification\n",
    "  - INDUSTRY_GROUP: Broader industry grouping\n",
    "  - SUB_INDUSTRY: Detailed industry subcategory\n",
    "  - SECTOR: High-level sector classification\n",
    "\n",
    "* **Time Series Features:**\n",
    "  - RET_1 to RET_20: Historical residual returns (20-day window)\n",
    "  - VOLUME_1 to VOLUME_20: Historical relative trading volumes (20-day window)\n",
    "\n",
    "### <a id='toc1_2_2_'></a>[Output Dataset Structure](#toc0_)\n",
    "* ID: Corresponding identifier\n",
    "* RET: Binary target indicating return direction (1 = up, 0 = down)\n",
    "\n",
    "------------------------------------------------------------------------------------------------\n",
    "### <a id='toc1_2_3_'></a>[Key Financial Calculations](#toc0_)\n",
    "\n",
    "**One-Day Return Formula:**\n",
    "$$R^t = \\frac{P_j^t}{P_j^{t-1}} - 1$$\n",
    "where:\n",
    "- $P_j^t$ is the price of stock j at time t\n",
    "- $P_j^{t-1}$ is the price at previous time period\n",
    "\n",
    "**Volume Normalization Process:**\n",
    "1. Calculate relative volume using 20-day median:\n",
    "$$\n",
    "\\tilde{V}^t_j = \\frac{V^t_j}{\\text{median}( \\{ V^{t-1}_j, \\ldots, V^{t-20}_j \\} )}\n",
    "$$\n",
    "\n",
    "2. Adjust for market-wide effects:\n",
    "$$\n",
    "V^t_j = \\tilde{V}^t_j - \\frac{1}{n} \\sum_{i=1}^{n} \\tilde{V}^t_i\n",
    "$$\n",
    "\n",
    "------------------------------------------------------------------------------------------------\n",
    "### <a id='toc1_2_4_'></a>[Dataset Scale](#toc0_)\n",
    "* Training set: 418,595 observations\n",
    "* Test set: 198,429 observations\n",
    "\n",
    "### <a id='toc1_2_5_'></a>[Submission Guidelines](#toc0_)\n",
    "Predictions must be formatted as a two-column file (ID, RET) matching test data IDs.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1d7cc5",
   "metadata": {},
   "source": [
    "## <a id='toc1_3_'></a>[Implementation Strategy](#toc0_)\n",
    "\n",
    "Our implementation follows a systematic approach across four major phases:\n",
    "#### <a id='toc1_3_1_1_'></a>[Project Roadmap](#toc0_)\n",
    "1. **Data Loading and Preprocessing**\n",
    "   - Robust data validation and quality checks\n",
    "   - Sophisticated missing value imputation\n",
    "   - Implementation of TA-Lib technical indicators\n",
    "   - Data cleaning including:\n",
    "     - Infinity value handling\n",
    "     - Duplicate column removal\n",
    "     - Training/test split optimization (75%/25%)\n",
    "\n",
    "2. **Feature Engineering**\n",
    "   - Technical indicator calculation:\n",
    "     - Relative Strength Index (RSI)\n",
    "     - On-Balance Volume (OBV)\n",
    "     - Exponential Moving Averages (EMA)\n",
    "   - Advanced feature engineering\n",
    "   - Feature selection and dimensionality reduction\n",
    "   - Target encoding of categorical variables\n",
    "   - Removal of redundant technical indicators\n",
    "\n",
    "3. **Model Development and Evaluation**\n",
    "   - Decision Tree Classifier\n",
    "      - Baseline implementation (accuracy: **0.510**)\n",
    "      - Advanced hyperparameter optimization (accuracy: **0.5325**)\n",
    "   - XGBoost Classifier\n",
    "      - Initial implementation (accuracy: **0.53**)\n",
    "      - Extensive hyperparameter tuning (accuracy: **0.8775**)\n",
    "   - Neural Network Architecture\n",
    "      - Custom feed-forward design\n",
    "      - Advanced loss function implementation\n",
    "      - Final accuracy: **0.5144**\n",
    "\n",
    "4. **Analysis and Validation**\n",
    "   - Cross-validation assessment\n",
    "   - Feature importance ranking and interpretation\n",
    "   - ROC curve analysis\n",
    "   - Confusion matrix evaluation\n",
    "   - Technical indicator assessment\n",
    "   - Benchmark comparison and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739111f7",
   "metadata": {},
   "source": [
    "## <a id='toc1_4_'></a>[Library Imports](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73ed10ed",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "try:\n",
    "    # VS Code\n",
    "    path = Path(__file__).parent.parent\n",
    "    path = path / \"src\"\n",
    "except NameError:\n",
    "    # jupyter notebook\n",
    "    path = Path().absolute().parent\n",
    "sys.path.append(str(path))\n",
    "\n",
    "import kedro.ipython\n",
    "from kedro.ipython import get_ipython\n",
    "\n",
    "kedro.ipython.load_ipython_extension(get_ipython())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b72927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging as log\n",
    "import warnings\n",
    "\n",
    "from IPython.display import Markdown as md\n",
    "\n",
    "from src.ml_in_finance_i_project.utils import get_node_idx, get_node_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8edfdc8",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "# Load the datasets\n",
    "x_train_raw = catalog.load(\"x_train_raw\")\n",
    "y_train_raw = catalog.load(\"y_train_raw\")\n",
    "x_test_raw = catalog.load(\"x_test_raw\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a18f63b",
   "metadata": {},
   "source": [
    "### <a id='toc1_4_1_'></a>[Environment Configuration and Setup](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b063f191",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## Google Colab Integration\n",
    "## Note: Must be executed before other library imports\n",
    "def setup_colab_environment():\n",
    "    \"\"\"\n",
    "    Establishes Google Colab environment with necessary configurations:\n",
    "    - Mounts Google Drive\n",
    "    - Creates required symbolic links\n",
    "    - Sets up project directory structure\n",
    "\n",
    "    Returns:\n",
    "        bool: True if running in Colab, False otherwise\n",
    "    \"\"\"\n",
    "    try:\n",
    "        import os\n",
    "\n",
    "        from google.colab import drive\n",
    "\n",
    "        drive.mount(\"/content/drive\")\n",
    "        req_symlinks = [\n",
    "            (\"data\", \"ml_in_finance_i_project/data\"),\n",
    "            (\"src\", \"ml_in_finance_i_project/src\"),\n",
    "        ]\n",
    "        # Create symlinks if they don't exist\n",
    "        for dest, src in req_symlinks:\n",
    "            if not os.path.exists(dest):\n",
    "                os.symlink(f\"/content/drive/Othercomputers/My Mac/{src}\", dest)\n",
    "        return True\n",
    "\n",
    "    except ImportError:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeef675a",
   "metadata": {},
   "source": [
    "#### <a id='toc1_4_1_1_'></a>[Pipeline Node Execution Configuration](#toc0_)\n",
    "Defining function for running specific pipeline nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59dcb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pipeline_node(pipeline_name: str, node_name: str, inputs: dict):\n",
    "    \"\"\"\n",
    "    Executes a specific node within the data processing pipeline.\n",
    "\n",
    "    Parameters:\n",
    "        pipeline_name (str): Target pipeline identifier\n",
    "        node_name (str): Specific node to execute\n",
    "        inputs (dict): Node input parameters\n",
    "\n",
    "    Returns:\n",
    "        Output from node execution\n",
    "    \"\"\"\n",
    "    node_idx = get_node_idx(pipelines[pipeline_name], node_name)\n",
    "    return pipelines[pipeline_name].nodes[node_idx].run(inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "269fd693",
   "metadata": {},
   "source": [
    "##### <a id='toc1_4_1_1_1_'></a>[Environment Initialization](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3238a731",
   "metadata": {},
   "outputs": [],
   "source": [
    "IN_COLAB = setup_colab_environment()\n",
    "\n",
    "# Configure logging to stdout\n",
    "log.basicConfig(\n",
    "    level=log.INFO,\n",
    "    format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
    "    handlers=[log.StreamHandler()],\n",
    ")\n",
    "conf_params = context.config_loader.get(\"parameters\")\n",
    "target = conf_params[\"model_options\"][\"target\"]\n",
    "kfold = conf_params[\"model_options\"][\"kfold\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93f6411f",
   "metadata": {},
   "source": [
    "## <a id='toc1_5_'></a>[Data Loading and Initial Processing](#toc0_)\n",
    "\n",
    "### <a id='toc1_5_1_'></a>[Preprocessing Strategy](#toc0_)\n",
    "* Handling of missing values (NA removal)\n",
    "* Target variable encoding (boolean to binary conversion)\n",
    "* Optional data subsetting capabilities:\n",
    "  - Fraction loading for rapid prototyping\n",
    "  - Time window selection (e.g., using first n days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a26a66",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "out = run_pipeline_node(\n",
    "    \"data_processing\",\n",
    "    \"load_data_node\",\n",
    "    {\n",
    "        \"x_train_raw\": x_train_raw,\n",
    "        \"y_train_raw\": y_train_raw,\n",
    "        \"x_test_raw\": x_test_raw,\n",
    "        \"params:sample_n\": conf_params[\"sample_n\"],\n",
    "    },\n",
    ")\n",
    "()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d367fea",
   "metadata": {},
   "source": [
    "#### <a id='toc1_5_1_1_'></a>[Visual Data Analysis](#toc0_)\n",
    "\n",
    "* Time series visualization of returns and volume\n",
    "* Target variable (RET) highlighted in red for clarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9bae98",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline_node(\n",
    "    \"reporting\",\n",
    "    \"plot_returns_volume_node\",\n",
    "    {\n",
    "        \"train_df\": out[\"train_df\"],\n",
    "        \"params:example_row_id\": 2,\n",
    "    },\n",
    ")[\"returns_volume_plot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c4097",
   "metadata": {},
   "source": [
    "#### <a id='toc1_5_1_2_'></a>[Initial Data Inspection](#toc0_)\n",
    "\n",
    "From visual inspection, we can see that there are missing / invalid values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c08fabd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "out[\"test_df\"].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a263855",
   "metadata": {},
   "source": [
    "#### <a id='toc1_5_1_3_'></a>[Dataset Information](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066ad264",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training Dataset Info:\")\n",
    "out[\"train_df\"].info()\n",
    "print(\"\\nTest Dataset Info:\")\n",
    "out[\"test_df\"].info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7893e5f0",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_2_'></a>[Missing Value Across Categories](#toc0_)\n",
    "\n",
    "\n",
    "#### <a id='toc1_5_2_1_'></a>[Possible Causes of Missing Data](#toc0_)\n",
    "\n",
    "1. **Market Structure**\n",
    "   - Weekend/holiday market closures\n",
    "   - Different trading venues (NYSE, NASDAQ, CBOE)\n",
    "\n",
    "2. **Data Quality Issues**\n",
    "   - Collection inconsistencies\n",
    "   - Date anonymization effects\n",
    "\n",
    "3. **Technical Computation Effects**\n",
    "   - Rolling window calculations (20-day impact)\n",
    "   - Weekend/holiday volume calculations\n",
    "\n",
    "4. **Market Events**\n",
    "   - Trading suspensions\n",
    "   - Stock delistings\n",
    "   - Low liquidity periods\n",
    "\n",
    "5. **Intentional Design**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84943c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_pipeline_node(\n",
    "    \"reporting\",\n",
    "    \"plot_nan_percentages_node\",\n",
    "    {\"train_df\": out[\"train_df\"]},\n",
    ")[\"nan_percentages_plot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12a85e2",
   "metadata": {},
   "source": [
    "#### <a id='toc1_5_2_2_'></a>[Class Balance Analysis](#toc0_)\n",
    "\n",
    "The target variable shows near-perfect class balance, which is expected given:\n",
    "1. The target represents return sign (+/-)\n",
    "2. Market efficiency theory implies roughly equal probability of up/down movements\n",
    "3. Slight positive bias may indicate:\n",
    "   - General market upward trend\n",
    "   - Risk premium effects\n",
    "   - Survivorship bias in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f421ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "md(\n",
    "    f\"Class imbalance: {out['train_df']['RET'].value_counts(normalize=True)[0] * 100:.2f}%\"\n",
    "    + f\" {out['train_df']['RET'].value_counts(normalize=True)[1] * 100:.2f}%\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf725f8",
   "metadata": {},
   "source": [
    "#### <a id='toc1_5_2_3_'></a>[Correlation Analysis](#toc0_)\n",
    "\n",
    "### <a id='toc1_5_3_'></a>[Key Findings:](#toc0_)\n",
    "\n",
    "1. **Return Correlations**\n",
    "   - Minimal cross-period return correlation (market efficiency)\n",
    "   - Stronger correlations between adjacent time periods\n",
    "   - Pattern suggests market efficiency (limited predictability)\n",
    "\n",
    "2. **Volume Relationships**\n",
    "   - Relatively high volume autocorrelation\n",
    "   - Volume clustering indicates market regime patterns\n",
    "   - Strong volume-volatility relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8e9337",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "out_corr = run_pipeline_node(\n",
    "    \"reporting\",\n",
    "    \"plot_correlation_matrix_node\",\n",
    "    {\"train_df\": out[\"train_df\"]},\n",
    ")\n",
    "out_corr[\"correlation_matrix_plot\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ebaa778",
   "metadata": {},
   "source": [
    "### <a id='toc1_5_4_'></a>[Preprocessing data](#toc0_)\n",
    "* Dropping rows with missing returns\n",
    "* Dropping NA values and ID columns\n",
    "* Converting target to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab472e08",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "out_preprocessed = run_pipeline_node(\n",
    "    \"data_processing\",\n",
    "    \"preprocess_data_node\",\n",
    "    {\"train_df\": out[\"train_df\"], \"test_df\": out[\"test_df\"]},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87dee303",
   "metadata": {},
   "source": [
    "## <a id='toc1_6_'></a>[Feature Engineering](#toc0_)\n",
    "\n",
    "* Extending variable set from competition organizers\n",
    "* Feature development based on technical analysis indicators\n",
    "* Statistical feature calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a515d951",
   "metadata": {},
   "outputs": [],
   "source": [
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    out2 = run_pipeline_node(\n",
    "        \"data_processing\",\n",
    "        \"calculate_statistical_features_node\",\n",
    "        {\n",
    "            \"train_df_preprocessed\": out_preprocessed[\"train_df_preprocessed\"],\n",
    "            \"test_df_preprocessed\": out_preprocessed[\"test_df_preprocessed\"],\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ea3c14",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_1_'></a>[Technical Indicator Implementation Using TA-Lib](#toc0_)\n",
    "\n",
    "This section implements advanced technical analysis indicators for both training and test datasets.\n",
    "Results are persisted to optimize computation time.\n",
    "\n",
    "#### <a id='toc1_6_1_1_'></a>[Implemented Indicators:](#toc0_)\n",
    "1. **Volume Indicators**\n",
    "   - On-Balance Volume (OBV)\n",
    "\n",
    "2. **Momentum Indicators**\n",
    "   - Relative Strength Index (RSI)\n",
    "   - Momentum (MOM) - 5 period\n",
    "   - Rate of Change Ratio (ROCR) - 5 period\n",
    "   - Chande Momentum Oscillator (CMO) - 14 period\n",
    "\n",
    "3. **Moving Averages**\n",
    "   - Exponential Moving Average (EMA) - 5 period\n",
    "   - Simple Moving Average (SMA) - 5 period\n",
    "   - Weighted Moving Average (WMA) - 5 period\n",
    "   - Midpoint Price (MIDPOINT) - 10 period\n",
    "\n",
    "Note: Computation is time-intensive for full dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c7b91b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate = False\n",
    "\n",
    "if calculate:\n",
    "    out3 = run_pipeline_node(\n",
    "        \"data_processing\",\n",
    "        \"calculate_technical_indicators_node\",\n",
    "        {\n",
    "            \"train_df_statistical_features\": out2[\"train_df_statistical_features\"],\n",
    "            \"test_df_statistical_features\": out2[\"test_df_statistical_features\"],\n",
    "            \"params:features_ret_vol\": conf_params[\"features_ret_vol\"],\n",
    "        },\n",
    "    )\n",
    "else:\n",
    "    out3 = get_node_outputs(\n",
    "        pipelines[\"data_processing\"].nodes[\n",
    "            get_node_idx(\n",
    "                pipelines[\"data_processing\"], \"calculate_technical_indicators_node\"\n",
    "            )\n",
    "        ],\n",
    "        catalog,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3effe60b",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_2_'></a>[Feature Selection Strategy](#toc0_)\n",
    "\n",
    "#### <a id='toc1_6_2_1_'></a>[Columns Targeted for Removal](#toc0_)\n",
    "1. **Identifier Columns**\n",
    "   - While potentially predictive, excluded for model generalization\n",
    "   - Includes: ID, STOCK, DATE\n",
    "\n",
    "2. ** Remaining Categorical Features**\n",
    "   - INDUSTRY, INDUSTRY_GROUP, SECTOR, SUB_INDUSTRY\n",
    "   - Used in feature engineering but removed from final model\n",
    "\n",
    "Rationale: Focus on price/volume dynamics rather than static characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd36cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "out4 = run_pipeline_node(\n",
    "    \"data_processing\",\n",
    "    \"drop_id_cols_node\",\n",
    "    {\n",
    "        \"train_ta_indicators\": out3[\"train_ta_indicators\"],\n",
    "        \"test_ta_indicators\": out3[\"test_ta_indicators\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88eb923",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_3_'></a>[Technical Indicator Optimization](#toc0_)\n",
    "\n",
    "#### <a id='toc1_6_3_1_'></a>[Indicator Selection Criteria](#toc0_)\n",
    "1. **Relevance**\n",
    "   - Remove indicators with minimal predictive value\n",
    "   - Focus on non-redundant signals\n",
    "\n",
    "2. **Complexity Reduction**\n",
    "   - Reduce feature space to prevent overfitting\n",
    "   - Example: Similar-period SMAs offer limited additional value\n",
    "\n",
    "3. **Model Performance Impact**\n",
    "   - Retain indicators that demonstrate predictive power\n",
    "   - Remove those that may introduce noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bfd751",
   "metadata": {},
   "outputs": [],
   "source": [
    "out5 = run_pipeline_node(\n",
    "    \"data_processing\",\n",
    "    \"drop_obsolete_technical_indicators_node\",\n",
    "    {\n",
    "        \"train_ta_indicators_dropped\": out4[\"train_ta_indicators_dropped\"],\n",
    "        \"test_ta_indicators_dropped\": out4[\"test_ta_indicators_dropped\"],\n",
    "        \"params:target\": conf_params[\"model_options\"][\"target\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7389b28b",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_4_'></a>[Data Quality Enhancement](#toc0_)\n",
    "\n",
    "#### <a id='toc1_6_4_1_'></a>[Infinity Value Management](#toc0_)\n",
    "* Critical for model stability\n",
    "* Particularly important for neural network training\n",
    "* Prevents numerical computation issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a1e9fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "out6 = run_pipeline_node(\n",
    "    \"data_processing\",\n",
    "    \"filter_infinity_values_node\",\n",
    "    {\n",
    "        \"train_df_technical_indicators\": out5[\"train_df_technical_indicators\"],\n",
    "        \"test_df_technical_indicators\": out5[\"test_df_technical_indicators\"],\n",
    "        \"params:target\": conf_params[\"model_options\"][\"target\"],\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56444445",
   "metadata": {},
   "source": [
    "### <a id='toc1_6_5_'></a>[Final Data Cleaning](#toc0_)\n",
    "\n",
    "#### <a id='toc1_6_5_1_'></a>[Quality Assurance Steps](#toc0_)\n",
    "1. **Duplicate Resolution**\n",
    "   - Remove redundant columns\n",
    "   - Ensure data uniqueness\n",
    "\n",
    "2. **Missing Value Treatment**\n",
    "   - Second-pass NaN handling\n",
    "   - Address gaps from technical indicator calculation\n",
    "\n",
    "Purpose: Ensure data quality for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f0b5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicated columns and handle NaN values\n",
    "out7 = run_pipeline_node(\n",
    "    \"data_processing\",\n",
    "    \"remove_duplicates_and_nans_node\",\n",
    "    {\n",
    "        \"train_df_filtered\": out6[\"train_df_filtered\"],\n",
    "        \"test_df_filtered\": out6[\"test_df_filtered\"],\n",
    "    },\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
